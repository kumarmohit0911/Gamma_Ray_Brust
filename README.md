Gamma-ray bursts (GRBs) are the most energetic explosions in the universe, often followed by multi-wavelength afterglows (X-ray, optical) that fade over time. Accurately predicting the brightness (flux) of a GRB’s afterglow based on its prompt gamma-ray emission parameters and context (e.g. redshift) is a challenging open problem in high-energy astrophysics. Such predictions would help allocate telescope resources for follow-up observations and probe GRB physics. We propose an advanced ML project that uses only fully-connected (MLP) neural networks – no CNNs, RNNs or transformers – to learn the nonlinear mapping from prompt-emission features and environmental factors to afterglow flux. This requires deep feature engineering to capture complex astrophysical relationships.


Most GRB studies use analytical or linear correlations; machine learning applications focus on classification (e.g. GRB type) rather than regression of afterglow intensity. We explicitly eschew CNN/RNN, forcing novel feature engineering (e.g. combining spectral parameters, fluence, redshift) to capture temporal/spatial effects in a static feature space. This “flat” approach is uncommon in GRB research, making it a novel contribution.
